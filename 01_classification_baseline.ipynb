{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635acdf2",
   "metadata": {},
   "source": [
    "# 01 â€” Baseline Image Classification (fastai, ResNet-34)\n",
    "Edit the config cell to point to your dataset, then run all cells.\n",
    "Outputs (ROC, confusion matrix, metrics) will be saved in `../reports`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da249c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/Imports (Kaggle usually has these preinstalled)\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c2187",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = Path('../configs/config.yaml').resolve()\n",
    "with open(config_path) as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36239cf2",
   "metadata": {},
   "source": [
    "## Data: ImageDataLoaders.from_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(CFG.get('random_seed', 42))\n",
    "\n",
    "dataset_root = Path(CFG['dataset_root'])  # update in config.yaml\n",
    "assert dataset_root.exists(), f\"Dataset path not found: {dataset_root}. Update configs/config.yaml\"\n",
    "\n",
    "# Build dataloaders: expects subfolders per class\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    dataset_root,\n",
    "    valid_pct=CFG['valid_pct'],\n",
    "    seed=CFG.get('random_seed', 42),\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(size=CFG['image_size'], min_scale=0.75),\n",
    "        Normalize.from_stats(*imagenet_stats)\n",
    "    ],\n",
    "    bs=CFG['bs']\n",
    ")\n",
    "\n",
    "dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28803a",
   "metadata": {},
   "source": [
    "## Model: ResNet-34 + fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe93ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = getattr(models, CFG['model_name'])\n",
    "learn = vision_learner(dls, arch, metrics=accuracy)\n",
    "learn.fine_tune(CFG['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e3cbb",
   "metadata": {},
   "source": [
    "## Evaluation: Confusion Matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_dir = (Path('../reports')).resolve()\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Confusion matrix\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "cm = interp.confusion_matrix()\n",
    "print(cm)\n",
    "interp.plot_confusion_matrix(figsize=(6,6))\n",
    "save_confusion = reports_dir/'cls_confusion_matrix.png'\n",
    "plt.savefig(save_confusion, bbox_inches='tight')\n",
    "print(f\"Saved: {save_confusion}\")\n",
    "\n",
    "# ROC (one-vs-rest if >2 classes)\n",
    "probs, targs = learn.get_preds()\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "    y_true = targs.cpu().numpy()\n",
    "    y_score = probs.cpu().numpy()\n",
    "    if y_score.shape[1] == 2:\n",
    "        auc = roc_auc_score(y_true, y_score[:,1])\n",
    "        RocCurveDisplay.from_predictions(y_true, y_score[:,1])\n",
    "    else:\n",
    "        # macro AUC for multi-class\n",
    "        auc = roc_auc_score(y_true, y_score, multi_class='ovr', average='macro')\n",
    "        # Plot ROC for each class\n",
    "        for c in range(y_score.shape[1]):\n",
    "            RocCurveDisplay.from_predictions((y_true==c).astype(int), y_score[:,c])\n",
    "    save_roc = reports_dir/'cls_roc.png'\n",
    "    plt.savefig(save_roc, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_roc}\")\n",
    "except Exception as e:\n",
    "    print(\"ROC computation skipped:\", e)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'accuracy': float(learn.validate()[1]),\n",
    "    'auc': float(auc) if 'auc' in locals() else None,\n",
    "    'classes': dls.vocab if hasattr(dls, 'vocab') else None\n",
    "}\n",
    "with open(reports_dir/'cls_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"Saved:\", reports_dir/'cls_metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f394d",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(reports_dir/'cls_export.pkl')\n",
    "print(\"Saved:\", reports_dir/'cls_export.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
